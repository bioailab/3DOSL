{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchmetrics as tm\n",
    "\n",
    "# Betti-Matching\n",
    "import sys\n",
    "sys.path.append('./Betti-Matching')\n",
    "from BettiMatching import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice and IoU\n",
    "def get_metrics(pred, gt):\n",
    "    dice = tm.functional.dice(torch.from_numpy(pred).to(device), torch.from_numpy(gt).to(device), ignore_index=0)\n",
    "    iou = tm.functional.classification.binary_jaccard_index(torch.from_numpy(pred).to(device), torch.from_numpy(gt).to(device))\n",
    "    return dice.item(), iou.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './test_data'\n",
    "test_files = glob.glob(os.path.join(DATA_DIR, '*.png'))\n",
    "test_files = [os.path.basename(f).replace('.png', '') for f in test_files]\n",
    "skip_files = [\n",
    "    # Only background pixels in these images\n",
    "    '13_009','13_008','24_005','13_004','17_004','17_016','17_009','17_014','13_013',\n",
    "    # These images do not work with mitometer\n",
    "    '6_013','29_004','14_005','2_013','21_012','6_003','21_016','2_004','14_001','9_013',\n",
    "    '21_013','2_014','2_008','2_003','21_008','24_016','14_011','2_009','24_012','6_004',\n",
    "    '6_014','21_009','9_004','29_013','14_012','21_014','24_008','21_004'\n",
    "]\n",
    "test_files = [f for f in test_files if f not in skip_files]  # Filtering out files that cause issues in evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS_PATH = './Prediction'\n",
    "GT_PATH = './test_gt'\n",
    "pred_files = [f'{PREDICTIONS_PATH}/{i}.tif'.replace('_', '-') for i in test_files]\n",
    "gt_files = [os.path.join(GT_PATH,\n",
    "                        os.path.basename(f)).replace('tif', 'png').replace('-', '_') for f in pred_files]\n",
    "img_files = [f.replace('test_gt', 'test_data') for f in gt_files]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice + IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the best examples\n",
    "for i in range(len(pred_files)):\n",
    "    pred = cv2.imread(pred_files[i], cv2.IMREAD_UNCHANGED) > 0\n",
    "    gt = cv2.imread(gt_files[i], cv2.IMREAD_UNCHANGED)[..., 0] == 255\n",
    "    img = cv2.imread(img_files[i], cv2.IMREAD_UNCHANGED)[..., 0]\n",
    "\n",
    "    # Dice and IoU\n",
    "    dice = tm.functional.dice(torch.from_numpy(pred).to(\n",
    "        device), torch.from_numpy(gt).to(device), ignore_index=0)\n",
    "    iou = tm.functional.classification.binary_jaccard_index(\n",
    "        torch.from_numpy(pred).to(device), torch.from_numpy(gt).to(device))\n",
    "\n",
    "    # Show the best examples\n",
    "    if dice.item() > 0.9:\n",
    "        print(\"Dice:\", dice.item(), \"IoU:\", iou.item())\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(30, 10))\n",
    "        plt.subplot(131)\n",
    "        plt.title('image')\n",
    "        plt.imshow(img)\n",
    "        plt.subplot(132)\n",
    "        plt.title('gt')\n",
    "        plt.imshow(gt)\n",
    "        plt.subplot(133)\n",
    "        plt.title('pred')\n",
    "        plt.imshow(pred)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for all images and save to csv\n",
    "preds = []\n",
    "gts = []\n",
    "dices = []\n",
    "ious = []\n",
    "images = []\n",
    "ids = []\n",
    "\n",
    "for i, (pred_file, gt_file, image_file) in enumerate(zip(pred_files, gt_files, img_files)):\n",
    "    preds.append(pred_file)\n",
    "    pred = cv2.imread(pred_file, cv2.IMREAD_UNCHANGED) > 0\n",
    "    gts.append(gt_file)\n",
    "    gt = cv2.imread(gt_file, cv2.IMREAD_UNCHANGED)[..., 0] == 255\n",
    "    images.append(image_file)\n",
    "\n",
    "    dice = tm.functional.dice(torch.from_numpy(pred).to(device), torch.from_numpy(gt).to(device), ignore_index=0)\n",
    "    iou = tm.functional.classification.binary_jaccard_index(torch.from_numpy(pred).to(device), torch.from_numpy(gt).to(device))\n",
    "    dices.append(dice.item())\n",
    "    ious.append(iou.item())\n",
    "    ids.append(i)\n",
    "    # print(i, dice.item(), iou.item())\n",
    "    print(f\"{i+1}/{len(pred_files)}\", end='\\r')\n",
    "\n",
    "df = pd.DataFrame({'id': ids, 'pred': preds, 'gt': gts,\n",
    "                'dice': dices, 'iou': ious, 'image': images})\n",
    "df.to_csv('neurips25_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['dice', 'iou']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for all images and save to csv\n",
    "preds = []\n",
    "gts = []\n",
    "images = []\n",
    "ids = []\n",
    "betty_errors = []\n",
    "betty_matching_losses = []\n",
    "\n",
    "for i, (pred_file, gt_file, image_file) in enumerate(zip(pred_files, gt_files, img_files)):\n",
    "    preds.append(pred_file)\n",
    "    pred = cv2.imread(pred_file, cv2.IMREAD_UNCHANGED) == 255\n",
    "    gts.append(gt_file)\n",
    "    gt = cv2.imread(gt_file, cv2.IMREAD_UNCHANGED)[..., 0] == 255\n",
    "    images.append(image_file)\n",
    "\n",
    "    b=BettiMatching(pred, gt, filtration='superlevel')\n",
    "    error, loss = b.Betti_number_error(), b.loss()\n",
    "    betty_errors.append(error)\n",
    "    betty_matching_losses.append(loss)    \n",
    "\n",
    "    ids.append(i)\n",
    "    print(f\"{i+1}/{len(pred_files)}\", end='\\r')\n",
    "\n",
    "df = pd.DataFrame({'id': ids, 'pred': preds, 'gt': gts,\n",
    "                'betty_error': betty_errors, 'betty_matching_loss': betty_matching_losses,\n",
    "                'image': images})\n",
    "df.to_csv('betty_neurips25_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['betty_error', 'betty_matching_loss']].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "side_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
